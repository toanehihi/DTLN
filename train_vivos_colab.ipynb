{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83c\udfa4 DTLN Model Training on Google Colab\n",
                "## Vietnamese Speech Enhancement with VIVOS Dataset\n",
                "\n",
                "This notebook trains the DTLN (Dual-Signal Transformation LSTM Network) model for speech enhancement using VIVOS dataset.\n",
                "\n",
                "**Features:**\n",
                "- \u2705 Complete self-contained notebook (all code embedded)\n",
                "- \u2705 Automatic checkpoint saving to Google Drive after each epoch  \n",
                "- \u2705 Resume training from last checkpoint\n",
                "- \u2705 Training progress logging\n",
                "- \u2705 GPU support\n",
                "- \u2705 No external files needed (model.py embedded)\n",
                "\n",
                "**Dataset:**\n",
                "- Created from VIVOS (clean speech) + DNS noise\n",
                "- Already prepared in `vivos_datasets/` directory"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Mount Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "# Mount Google Drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Set working directory\n",
                "DRIVE_PATH = '/content/drive/MyDrive/DTLN'\n",
                "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
                "os.chdir(DRIVE_PATH)\n",
                "\n",
                "print(f\"\u2705 Mounted Google Drive\")\n",
                "print(f\"\ud83d\udcc1 Working directory: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q soundfile wavinfo\n",
                "\n",
                "import tensorflow as tf\n",
                "print(f\"TensorFlow version: {tf.__version__}\")\n",
                "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== CONFIGURATION ====================\n",
                "# Dataset paths (relative to DRIVE_PATH)\n",
                "PATH_TO_TRAIN_MIX = 'vivos_datasets/train/noisy'\n",
                "PATH_TO_TRAIN_SPEECH = 'vivos_datasets/train/clean'\n",
                "PATH_TO_VAL_MIX = 'vivos_datasets/val/noisy'\n",
                "PATH_TO_VAL_SPEECH = 'vivos_datasets/val/clean'\n",
                "\n",
                "# Checkpoint directory\n",
                "CHECKPOINT_DIR = 'vivos_checkpoints'\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "\n",
                "# Training run name\n",
                "RUN_NAME = 'DTLN_vivos'\n",
                "\n",
                "# Model hyperparameters\n",
                "BATCH_SIZE = 64\n",
                "MAX_EPOCHS = 50\n",
                "LEARNING_RATE = 1e-3\n",
                "SAMPLE_LENGTH_SECONDS = 15\n",
                "\n",
                "# Resume training from checkpoint?\n",
                "RESUME_FROM_CHECKPOINT = True\n",
                "\n",
                "print(\"\u2705 Configuration loaded\")\n",
                "print(f\"\ud83d\udcca Batch size: {BATCH_SIZE}\")\n",
                "print(f\"\ud83d\udcca Max epochs: {MAX_EPOCHS}\")\n",
                "print(f\"\ud83d\udcca Learning rate: {LEARNING_RATE}\")\n",
                "print(f\"\ud83d\udcca Sample length: {SAMPLE_LENGTH_SECONDS}s\")\n",
                "print(f\"\ud83d\udcbe Checkpoint dir: {CHECKPOINT_DIR}\")\n",
                "print(f\"\ud83d\udd04 Resume training: {RESUME_FROM_CHECKPOINT}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. DTLN Model Code (Embedded)\n",
                "\n",
                "Complete DTLN model implementation embedded directly in notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, fnmatch\n",
                "import csv\n",
                "import tensorflow.keras as keras\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.layers import Activation, Dense, LSTM, Dropout, \\\n",
                "    Lambda, Input, Multiply, Layer, Conv1D\n",
                "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger, \\\n",
                "    EarlyStopping, ModelCheckpoint\n",
                "import tensorflow as tf\n",
                "import soundfile as sf\n",
                "from wavinfo import WavInfoReader\n",
                "from random import shuffle, seed\n",
                "import numpy as np\n",
                "\n",
                "\n",
                "class audio_generator():\n",
                "    '''\n",
                "    Class to create a Tensorflow dataset based on an iterator from a large scale \n",
                "    audio dataset. This audio generator only supports single channel audio files.\n",
                "    '''\n",
                "    \n",
                "    def __init__(self, path_to_input, path_to_s1, len_of_samples, fs, train_flag=False):\n",
                "        '''\n",
                "        Constructor of the audio generator class.\n",
                "        '''\n",
                "        self.path_to_input = path_to_input\n",
                "        self.path_to_s1 = path_to_s1\n",
                "        self.len_of_samples = len_of_samples\n",
                "        self.fs = fs\n",
                "        self.train_flag=train_flag\n",
                "        self.count_samples()\n",
                "        self.create_tf_data_obj()\n",
                "        \n",
                "    def count_samples(self):\n",
                "        '''Method to list the data of the dataset and count the number of samples.'''\n",
                "        self.file_names = fnmatch.filter(os.listdir(self.path_to_input), '*.wav')\n",
                "        self.total_samples = 0\n",
                "        for file in self.file_names:\n",
                "            info = WavInfoReader(os.path.join(self.path_to_input, file))\n",
                "            self.total_samples = self.total_samples + \\\n",
                "                int(np.fix(info.data.frame_count/self.len_of_samples))\n",
                "    \n",
                "    def create_generator(self):\n",
                "        '''Method to create the iterator.'''\n",
                "        if self.train_flag:\n",
                "            shuffle(self.file_names)\n",
                "        for file in self.file_names:\n",
                "            noisy, fs_1 = sf.read(os.path.join(self.path_to_input, file))\n",
                "            speech, fs_2 = sf.read(os.path.join(self.path_to_s1, file))  # Same filename\n",
                "            \n",
                "            if fs_1 != self.fs or fs_2 != self.fs:\n",
                "                raise ValueError('Sampling rates do not match.')\n",
                "            if noisy.ndim != 1 or speech.ndim != 1:\n",
                "                raise ValueError('Too many audio channels.')\n",
                "            \n",
                "            num_samples = int(np.fix(noisy.shape[0]/self.len_of_samples))\n",
                "            for idx in range(num_samples):\n",
                "                in_dat = noisy[int(idx*self.len_of_samples):int((idx+1)*self.len_of_samples)]\n",
                "                tar_dat = speech[int(idx*self.len_of_samples):int((idx+1)*self.len_of_samples)]\n",
                "                yield in_dat.astype('float32'), tar_dat.astype('float32')\n",
                "\n",
                "    def create_tf_data_obj(self):\n",
                "        '''Method to create the tf.data.Dataset.'''\n",
                "        self.tf_data_set = tf.data.Dataset.from_generator(\n",
                "                        self.create_generator,\n",
                "                        (tf.float32, tf.float32),\n",
                "                        output_shapes=(tf.TensorShape([self.len_of_samples]), \n",
                "                                       tf.TensorShape([self.len_of_samples])),\n",
                "                        args=None)\n",
                "\n",
                "\n",
                "class InstantLayerNormalization(Layer):\n",
                "    '''Instant layer normalization layer'''\n",
                "    def __init__(self, **kwargs):\n",
                "        super(InstantLayerNormalization, self).__init__(**kwargs)\n",
                "        self.epsilon = 1e-7 \n",
                "        self.gamma = None\n",
                "        self.beta = None\n",
                "\n",
                "    def build(self, input_shape):\n",
                "        shape = input_shape[-1:]\n",
                "        self.gamma = self.add_weight(shape=shape, initializer='ones', trainable=True, name='gamma')\n",
                "        self.beta = self.add_weight(shape=shape, initializer='zeros', trainable=True, name='beta')\n",
                "\n",
                "    def call(self, inputs):\n",
                "        mean = tf.math.reduce_mean(inputs, axis=[-1], keepdims=True)\n",
                "        variance = tf.math.reduce_mean(tf.math.square(inputs - mean), axis=[-1], keepdims=True)\n",
                "        std = tf.math.sqrt(variance + self.epsilon)\n",
                "        outputs = (inputs - mean) / std\n",
                "        outputs = outputs * self.gamma + self.beta\n",
                "        return outputs\n",
                "\n",
                "\n",
                "class DTLN_model():\n",
                "    '''Class to create and train the DTLN model'''\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.cost_function = self.snr_cost\n",
                "        self.model = []\n",
                "        # Default parameters\n",
                "        self.fs = 16000\n",
                "        self.batchsize = 64\n",
                "        self.len_samples = 15\n",
                "        self.activation = 'sigmoid'\n",
                "        self.numUnits = 128\n",
                "        self.numLayer = 2\n",
                "        self.blockLen = 512\n",
                "        self.block_shift = 128\n",
                "        self.dropout = 0.25\n",
                "        self.lr = 1e-3 \n",
                "        self.max_epochs = 50\n",
                "        self.encoder_size = 256\n",
                "        self.eps = 1e-7\n",
                "        \n",
                "        # Set seeds\n",
                "        os.environ['PYTHONHASHSEED']=str(42)\n",
                "        seed(42)\n",
                "        np.random.seed(42)\n",
                "        tf.random.set_seed(42)\n",
                "        \n",
                "        # GPU memory growth\n",
                "        physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
                "        if len(physical_devices) > 0:\n",
                "            for device in physical_devices:\n",
                "                tf.config.experimental.set_memory_growth(device, enable=True)\n",
                "\n",
                "    @staticmethod\n",
                "    def snr_cost(s_estimate, s_true):\n",
                "        '''SNR cost function'''\n",
                "        snr = tf.reduce_mean(tf.math.square(s_true), axis=-1, keepdims=True) / \\\n",
                "            (tf.reduce_mean(tf.math.square(s_true-s_estimate), axis=-1, keepdims=True)+1e-7)\n",
                "        num = tf.math.log(snr) \n",
                "        denom = tf.math.log(tf.constant(10, dtype=num.dtype))\n",
                "        loss = -10*(num / (denom))\n",
                "        return loss\n",
                "\n",
                "    def lossWrapper(self):\n",
                "        '''Wrapper for loss function'''\n",
                "        def lossFunction(y_true,y_pred):\n",
                "            loss = tf.squeeze(self.cost_function(y_pred,y_true))\n",
                "            loss = tf.reduce_mean(loss)\n",
                "            return loss\n",
                "        return lossFunction\n",
                "\n",
                "    def stftLayer(self, x):\n",
                "        '''STFT layer'''\n",
                "        frames = tf.signal.frame(x, self.blockLen, self.block_shift)\n",
                "        stft_dat = tf.signal.rfft(frames)\n",
                "        mag = tf.abs(stft_dat)\n",
                "        phase = tf.math.angle(stft_dat)\n",
                "        return [mag, phase]\n",
                "    \n",
                "    def fftLayer(self, x):\n",
                "        '''FFT layer'''\n",
                "        frame = tf.expand_dims(x, axis=1)\n",
                "        stft_dat = tf.signal.rfft(frame)\n",
                "        mag = tf.abs(stft_dat)\n",
                "        phase = tf.math.angle(stft_dat)\n",
                "        return [mag, phase]\n",
                "\n",
                "    def ifftLayer(self, x):\n",
                "        '''Inverse FFT layer'''\n",
                "        s1_stft = (tf.cast(x[0], tf.complex64) * tf.exp( (1j * tf.cast(x[1], tf.complex64))))\n",
                "        return tf.signal.irfft(s1_stft)  \n",
                "\n",
                "    def overlapAddLayer(self, x):\n",
                "        '''Overlap and add layer'''\n",
                "        return tf.signal.overlap_and_add(x, self.block_shift)\n",
                "\n",
                "    def seperation_kernel(self, num_layer, mask_size, x, stateful=False):\n",
                "        '''Separation kernel with LSTM layers'''\n",
                "        for idx in range(num_layer):\n",
                "            x = LSTM(self.numUnits, return_sequences=True, stateful=stateful)(x)\n",
                "            if idx<(num_layer-1):\n",
                "                x = Dropout(self.dropout)(x)\n",
                "        mask = Dense(mask_size)(x)\n",
                "        mask = Activation(self.activation)(mask)\n",
                "        return mask\n",
                "\n",
                "    def build_DTLN_model(self, norm_stft=False):\n",
                "        '''Build DTLN model'''\n",
                "        time_dat = Input(batch_shape=(None, None))\n",
                "        mag,angle = Lambda(self.stftLayer)(time_dat)\n",
                "        \n",
                "        if norm_stft:\n",
                "            mag_norm = InstantLayerNormalization()(tf.math.log(mag + 1e-7))\n",
                "        else:\n",
                "            mag_norm = mag\n",
                "        \n",
                "        mask_1 = self.seperation_kernel(self.numLayer, (self.blockLen//2+1), mag_norm)\n",
                "        estimated_mag = Multiply()([mag, mask_1])\n",
                "        estimated_frames_1 = Lambda(self.ifftLayer)([estimated_mag,angle])\n",
                "        encoded_frames = Conv1D(self.encoder_size,1,strides=1,use_bias=False)(estimated_frames_1)\n",
                "        encoded_frames_norm = InstantLayerNormalization()(encoded_frames)\n",
                "        mask_2 = self.seperation_kernel(self.numLayer, self.encoder_size, encoded_frames_norm)\n",
                "        estimated = Multiply()([encoded_frames, mask_2]) \n",
                "        decoded_frames = Conv1D(self.blockLen, 1, padding='causal',use_bias=False)(estimated)\n",
                "        estimated_sig = Lambda(self.overlapAddLayer)(decoded_frames)\n",
                "        \n",
                "        self.model = Model(inputs=time_dat, outputs=estimated_sig)\n",
                "        print(self.model.summary())\n",
                "\n",
                "    def compile_model(self):\n",
                "        '''Compile model with optimizer and loss'''\n",
                "        optimizerAdam = keras.optimizers.Adam(learning_rate=self.lr, clipnorm=3.0)\n",
                "        self.model.compile(loss=self.lossWrapper(), optimizer=optimizerAdam)\n",
                "\n",
                "print(\"\u2705 DTLN model code loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Check Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import fnmatch\n",
                "\n",
                "def check_dataset_path(path, name):\n",
                "    \"\"\"Check if dataset path exists and count files\"\"\"\n",
                "    if os.path.exists(path):\n",
                "        files = fnmatch.filter(os.listdir(path), '*.wav')\n",
                "        print(f\"\u2705 {name}: {len(files)} files found at {path}\")\n",
                "        return len(files)\n",
                "    else:\n",
                "        print(f\"\u274c {name}: Path not found - {path}\")\n",
                "        return 0\n",
                "\n",
                "print(\"\ud83d\udd0d Checking datasets...\\n\")\n",
                "train_noisy = check_dataset_path(PATH_TO_TRAIN_MIX, \"Training Noisy\")\n",
                "train_clean = check_dataset_path(PATH_TO_TRAIN_SPEECH, \"Training Clean\")\n",
                "val_noisy = check_dataset_path(PATH_TO_VAL_MIX, \"Validation Noisy\")\n",
                "val_clean = check_dataset_path(PATH_TO_VAL_SPEECH, \"Validation Clean\")\n",
                "\n",
                "if train_noisy > 0 and train_clean > 0 and val_noisy > 0 and val_clean > 0:\n",
                "    print(\"\\n\u2705 All dataset paths are valid!\")\n",
                "    print(f\"\\n\ud83d\udcca Dataset info:\")\n",
                "    print(f\"   Train pairs: {train_noisy:,}\")\n",
                "    print(f\"   Val pairs:   {val_noisy:,}\")\n",
                "    print(f\"   Total pairs: {train_noisy + val_noisy:,}\")\n",
                "else:\n",
                "    print(\"\\n\u26a0\ufe0f Warning: Some dataset paths are missing or empty!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Create and Build Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create model instance\n",
                "model_trainer = DTLN_model()\n",
                "\n",
                "# Set custom parameters\n",
                "model_trainer.batchsize = BATCH_SIZE\n",
                "model_trainer.max_epochs = MAX_EPOCHS\n",
                "model_trainer.lr = LEARNING_RATE\n",
                "model_trainer.len_samples = SAMPLE_LENGTH_SECONDS\n",
                "\n",
                "# Build the model\n",
                "print(\"\ud83c\udfd7\ufe0f Building DTLN model...\")\n",
                "model_trainer.build_DTLN_model(norm_stft=False)\n",
                "print(\"\\n\u2705 Model built successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Load Checkpoint (if resuming)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "import re\n",
                "\n",
                "def get_latest_checkpoint(checkpoint_dir, run_name):\n",
                "    \"\"\"Find the latest checkpoint file\"\"\"\n",
                "    pattern = os.path.join(checkpoint_dir, f\"{run_name}_epoch_*.weights.weights.h5\")\n",
                "    checkpoints = glob.glob(pattern)\n",
                "    \n",
                "    if not checkpoints:\n",
                "        main_checkpoint = os.path.join(checkpoint_dir, f\"{run_name}.weights.h5\")\n",
                "        if os.path.exists(main_checkpoint):\n",
                "            return main_checkpoint, 0\n",
                "        return None, 0\n",
                "    \n",
                "    checkpoint_epochs = []\n",
                "    for cp in checkpoints:\n",
                "        match = re.search(r'epoch_(\\d+)', cp)\n",
                "        if match:\n",
                "            checkpoint_epochs.append((int(match.group(1)), cp))\n",
                "    \n",
                "    if checkpoint_epochs:\n",
                "        checkpoint_epochs.sort(reverse=True)\n",
                "        latest_epoch, latest_checkpoint = checkpoint_epochs[0]\n",
                "        return latest_checkpoint, latest_epoch\n",
                "    \n",
                "    return None, 0\n",
                "\n",
                "# Check for existing checkpoints\n",
                "initial_epoch = 0\n",
                "\n",
                "if RESUME_FROM_CHECKPOINT:\n",
                "    latest_checkpoint, checkpoint_epoch = get_latest_checkpoint(CHECKPOINT_DIR, RUN_NAME)\n",
                "    \n",
                "    if latest_checkpoint:\n",
                "        print(f\"\ud83d\udce5 Loading checkpoint from: {latest_checkpoint}\")\n",
                "        print(f\"\ud83d\udcca Resuming from epoch: {checkpoint_epoch}\")\n",
                "        try:\n",
                "            model_trainer.model.load_weights(latest_checkpoint)\n",
                "            initial_epoch = checkpoint_epoch\n",
                "            print(\"\u2705 Checkpoint loaded successfully!\")\n",
                "        except Exception as e:\n",
                "            print(f\"\u26a0\ufe0f Failed to load checkpoint: {e}\")\n",
                "            print(\"Starting training from scratch...\")\n",
                "            initial_epoch = 0\n",
                "    else:\n",
                "        print(\"\u2139\ufe0f No checkpoint found. Starting training from scratch...\")\n",
                "else:\n",
                "    print(\"\u2139\ufe0f Resume from checkpoint disabled. Starting fresh training...\")\n",
                "\n",
                "print(f\"\\n\ud83c\udfc1 Will start training from epoch: {initial_epoch + 1}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Compile Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\u2699\ufe0f Compiling model...\")\n",
                "model_trainer.compile_model()\n",
                "print(\"\u2705 Model compiled successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Setup Callbacks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
                "import shutil\n",
                "\n",
                "class DriveCheckpointCallback(Callback):\n",
                "    \"\"\"Custom callback to save checkpoint to Google Drive after each epoch\"\"\"\n",
                "    \n",
                "    def __init__(self, checkpoint_dir, run_name):\n",
                "        super().__init__()\n",
                "        self.checkpoint_dir = checkpoint_dir\n",
                "        self.run_name = run_name\n",
                "        self.best_val_loss = float('inf')\n",
                "        \n",
                "    def on_epoch_end(self, epoch, logs=None):\n",
                "        # Save epoch checkpoint\n",
                "        epoch_checkpoint_path = os.path.join(\n",
                "            self.checkpoint_dir, \n",
                "            f\"{self.run_name}_epoch_{epoch+1:03d}.weights.h5\"\n",
                "        )\n",
                "        \n",
                "        print(f\"\\n\ud83d\udcbe Saving checkpoint to Google Drive: {epoch_checkpoint_path}\")\n",
                "        self.model.save_weights(epoch_checkpoint_path)\n",
                "        \n",
                "        # Save as latest\n",
                "        latest_checkpoint_path = os.path.join(\n",
                "            self.checkpoint_dir,\n",
                "            f\"{self.run_name}_latest.weights.h5\"\n",
                "        )\n",
                "        shutil.copy(epoch_checkpoint_path, latest_checkpoint_path)\n",
                "        \n",
                "        # Save best model\n",
                "        val_loss = logs.get('val_loss')\n",
                "        if val_loss and val_loss < self.best_val_loss:\n",
                "            self.best_val_loss = val_loss\n",
                "            best_checkpoint_path = os.path.join(\n",
                "                self.checkpoint_dir,\n",
                "                f\"{self.run_name}_best.weights.h5\"\n",
                "            )\n",
                "            shutil.copy(epoch_checkpoint_path, best_checkpoint_path)\n",
                "            print(f\"\u2b50 New best model saved! Val Loss: {val_loss:.4f}\")\n",
                "        \n",
                "        # Keep only last 3 epoch checkpoints\n",
                "        self._cleanup_old_checkpoints(keep_last=3)\n",
                "        print(f\"\u2705 Checkpoint saved successfully!\")\n",
                "    \n",
                "    def _cleanup_old_checkpoints(self, keep_last=3):\n",
                "        pattern = os.path.join(self.checkpoint_dir, f\"{self.run_name}_epoch_*.weights.h5\")\n",
                "        checkpoints = glob.glob(pattern)\n",
                "        \n",
                "        if len(checkpoints) > keep_last:\n",
                "            checkpoints.sort(key=os.path.getmtime)\n",
                "            for old_checkpoint in checkpoints[:-keep_last]:\n",
                "                try:\n",
                "                    os.remove(old_checkpoint)\n",
                "                    print(f\"\ud83d\uddd1\ufe0f Removed old checkpoint: {os.path.basename(old_checkpoint)}\")\n",
                "                except Exception as e:\n",
                "                    print(f\"\u26a0\ufe0f Failed to remove {old_checkpoint}: {e}\")\n",
                "\n",
                "# Create callbacks\n",
                "save_path = os.path.join(CHECKPOINT_DIR, RUN_NAME)\n",
                "os.makedirs(save_path, exist_ok=True)\n",
                "\n",
                "drive_checkpoint_callback = DriveCheckpointCallback(CHECKPOINT_DIR, RUN_NAME)\n",
                "csv_logger = CSVLogger(os.path.join(save_path, f'training_{RUN_NAME}.log'), append=True)\n",
                "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-10, cooldown=1, verbose=1)\n",
                "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto', baseline=None)\n",
                "\n",
                "callbacks = [\n",
                "    drive_checkpoint_callback,\n",
                "    csv_logger,\n",
                "    reduce_lr,\n",
                "    early_stopping\n",
                "]\n",
                "\n",
                "print(\"\u2705 Training callbacks configured!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Prepare Data Generators"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate sample length\n",
                "len_in_samples = int(np.fix(\n",
                "    model_trainer.fs * model_trainer.len_samples / model_trainer.block_shift\n",
                ") * model_trainer.block_shift)\n",
                "\n",
                "print(f\"\ud83c\udfb5 Audio sample length: {len_in_samples} samples ({len_in_samples/model_trainer.fs:.2f} seconds)\")\n",
                "print(f\"\\n\ud83d\udcca Creating data generators...\")\n",
                "\n",
                "# Create training data generator\n",
                "print(\"   Loading training data...\")\n",
                "generator_input = audio_generator(\n",
                "    PATH_TO_TRAIN_MIX,\n",
                "    PATH_TO_TRAIN_SPEECH,\n",
                "    len_in_samples,\n",
                "    model_trainer.fs,\n",
                "    train_flag=True\n",
                ")\n",
                "\n",
                "dataset = generator_input.tf_data_set\n",
                "dataset = dataset.batch(model_trainer.batchsize, drop_remainder=True).repeat()\n",
                "steps_train = generator_input.total_samples // model_trainer.batchsize\n",
                "\n",
                "print(f\"   \u2705 Training samples: {generator_input.total_samples:,}\")\n",
                "print(f\"   \u2705 Training steps per epoch: {steps_train:,}\")\n",
                "\n",
                "# Create validation data generator  \n",
                "print(\"\\n   Loading validation data...\")\n",
                "generator_val = audio_generator(\n",
                "    PATH_TO_VAL_MIX,\n",
                "    PATH_TO_VAL_SPEECH,\n",
                "    len_in_samples,\n",
                "    model_trainer.fs\n",
                ")\n",
                "\n",
                "dataset_val = generator_val.tf_data_set\n",
                "dataset_val = dataset_val.batch(model_trainer.batchsize, drop_remainder=True).repeat()\n",
                "steps_val = generator_val.total_samples // model_trainer.batchsize\n",
                "\n",
                "print(f\"   \u2705 Validation samples: {generator_val.total_samples:,}\")\n",
                "print(f\"   \u2705 Validation steps: {steps_val:,}\")\n",
                "\n",
                "print(\"\\n\u2705 Data generators ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Start Training \ud83d\ude80"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"\ud83d\ude80 STARTING TRAINING\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\ud83d\udcca Configuration:\")\n",
                "print(f\"   Batch size: {model_trainer.batchsize}\")\n",
                "print(f\"   Max epochs: {model_trainer.max_epochs}\")\n",
                "print(f\"   Initial epoch: {initial_epoch + 1}\")\n",
                "print(f\"   Learning rate: {model_trainer.lr}\")\n",
                "print(f\"   Training steps: {steps_train:,}\")\n",
                "print(f\"   Validation steps: {steps_val:,}\")\n",
                "print(f\"\\n\ud83d\udcbe Checkpoints will be saved to: {CHECKPOINT_DIR}\")\n",
                "print(\"=\"*60 + \"\\n\")\n",
                "\n",
                "# Start training\n",
                "history = model_trainer.model.fit(\n",
                "    x=dataset,\n",
                "    batch_size=None,\n",
                "    steps_per_epoch=steps_train,\n",
                "    epochs=model_trainer.max_epochs,\n",
                "    initial_epoch=initial_epoch,\n",
                "    verbose=1,\n",
                "    validation_data=dataset_val,\n",
                "    validation_steps=steps_val,\n",
                "    callbacks=callbacks,\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"\u2705 TRAINING COMPLETED!\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Plot Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.figure(figsize=(12, 4))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history.history['loss'], label='Training Loss')\n",
                "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
                "plt.title('Model Loss')\n",
                "plt.ylabel('Loss')\n",
                "plt.xlabel('Epoch')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history.history['loss'], label='Training Loss')\n",
                "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
                "plt.title('Model Loss (Log Scale)')\n",
                "plt.ylabel('Loss (log)')\n",
                "plt.xlabel('Epoch')\n",
                "plt.yscale('log')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(CHECKPOINT_DIR, f'{RUN_NAME}_training_history.png'), dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(f\"\u2705 Training history plot saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Save Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model weights\n",
                "final_model_path = os.path.join(CHECKPOINT_DIR, f\"{RUN_NAME}_final.weights.h5\")\n",
                "model_trainer.model.save_weights(final_model_path)\n",
                "print(f\"\u2705 Final model saved to: {final_model_path}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"  TRAINING SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\u2705 Training completed successfully!\")\n",
                "print(f\"\\n\ud83d\udcc1 All files saved to Google Drive:\")\n",
                "print(f\"   Location: {CHECKPOINT_DIR}\")\n",
                "print(f\"\\n\ud83d\udcbe Checkpoint files:\")\n",
                "print(f\"   \u2022 Best model: {RUN_NAME}_best.weights.h5\")\n",
                "print(f\"   \u2022 Final model: {RUN_NAME}_final.weights.h5\")\n",
                "print(f\"   \u2022 Latest checkpoint: {RUN_NAME}_latest.weights.h5\")\n",
                "print(f\"\\n\ud83d\udcc8 Training log:\")\n",
                "print(f\"   \u2022 training_{RUN_NAME}.log\")\n",
                "print(f\"\\n\ud83c\udfa8 Visualization:\")\n",
                "print(f\"   \u2022 {RUN_NAME}_training_history.png\")\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"\u2728 To resume training later, just run this notebook again!\")\n",
                "print(\"\u2728 Make sure RESUME_FROM_CHECKPOINT = True\")\n",
                "print(\"=\"*60 + \"\\n\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}