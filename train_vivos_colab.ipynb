{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbXAp8TMuRgg"
      },
      "source": [
        "# ğŸ¤ DTLN Model Training on Google Colab\n",
        "## Vietnamese Speech Enhancement with VIVOS Dataset\n",
        "\n",
        "This notebook trains the DTLN (Dual-Signal Transformation LSTM Network) model for speech enhancement using VIVOS dataset.\n",
        "\n",
        "**Features:**\n",
        "- âœ… Complete self-contained notebook (all code embedded)\n",
        "- âœ… Automatic checkpoint saving to Google Drive after each epoch  \n",
        "- âœ… Resume training from last checkpoint\n",
        "- âœ… Training progress logging\n",
        "- âœ… GPU support\n",
        "- âœ… No external files needed (model.py embedded)\n",
        "\n",
        "**Dataset:**\n",
        "- Created from VIVOS (clean speech) + DNS noise\n",
        "- Already prepared in `vivos_datasets/` directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSxKiFRJuRgi"
      },
      "source": [
        "## 1. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym7Kd4UruRgj",
        "outputId": "efb02df6-ee8b-4525-a0f7-e1f2933af337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Mounted Google Drive\n",
            "ğŸ“ Working directory: /content/drive/MyDrive/workspace/DTLN\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set working directory\n",
        "DRIVE_PATH = '/content/drive/MyDrive/workspace/DTLN'\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "os.chdir(DRIVE_PATH)\n",
        "\n",
        "print(f\"âœ… Mounted Google Drive\")\n",
        "print(f\"ğŸ“ Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z76W26X5uRgm"
      },
      "source": [
        "## 2. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO_-gEZCuRgm",
        "outputId": "7a00072f-f61d-46bf-c602-2436ac5baf6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU Available: []\n"
          ]
        }
      ],
      "source": [
        "!pip install -q soundfile wavinfo\n",
        "\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH23eTrkuRgn"
      },
      "source": [
        "## 3. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXw7CjzDuRgn",
        "outputId": "18e6a90b-d73d-4789-8b5b-f2b6402fcccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Configuration loaded\n",
            "ğŸ“Š Batch size: 64\n",
            "ğŸ“Š Max epochs: 100\n",
            "ğŸ“Š Learning rate: 0.001\n",
            "ğŸ“Š Sample length: 3s\n",
            "ğŸ’¾ Checkpoint dir: vivos_checkpoints\n",
            "ğŸ”„ Resume training: True\n"
          ]
        }
      ],
      "source": [
        "# ==================== CONFIGURATION ====================\n",
        "# Dataset paths (relative to DRIVE_PATH)\n",
        "PATH_TO_TRAIN_MIX = 'vivos_datasets/train/noisy'\n",
        "PATH_TO_TRAIN_SPEECH = 'vivos_datasets/train/clean'\n",
        "PATH_TO_VAL_MIX = 'vivos_datasets/val/noisy'\n",
        "PATH_TO_VAL_SPEECH = 'vivos_datasets/val/clean'\n",
        "\n",
        "# Checkpoint directory\n",
        "CHECKPOINT_DIR = 'vivos_checkpoints'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Training run name\n",
        "RUN_NAME = 'DTLN_vivos'\n",
        "\n",
        "# Model hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "MAX_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-3\n",
        "SAMPLE_LENGTH_SECONDS = 3\n",
        "\n",
        "# Resume training from checkpoint?\n",
        "RESUME_FROM_CHECKPOINT = True\n",
        "\n",
        "print(\"âœ… Configuration loaded\")\n",
        "print(f\"ğŸ“Š Batch size: {BATCH_SIZE}\")\n",
        "print(f\"ğŸ“Š Max epochs: {MAX_EPOCHS}\")\n",
        "print(f\"ğŸ“Š Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"ğŸ“Š Sample length: {SAMPLE_LENGTH_SECONDS}s\")\n",
        "print(f\"ğŸ’¾ Checkpoint dir: {CHECKPOINT_DIR}\")\n",
        "print(f\"ğŸ”„ Resume training: {RESUME_FROM_CHECKPOINT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R4IBqNHuRgo"
      },
      "source": [
        "## 4. DTLN Model Code (Embedded)\n",
        "\n",
        "Complete DTLN model implementation embedded directly in notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C3fMn9huRgo",
        "outputId": "f2b3f61f-1622-444f-fdae-7af5d531f333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… DTLN model code loaded\n"
          ]
        }
      ],
      "source": [
        "import os, fnmatch\n",
        "import csv\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Activation, Dense, LSTM, Dropout, \\\n",
        "    Lambda, Input, Multiply, Layer, Conv1D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger, \\\n",
        "    EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import soundfile as sf\n",
        "from wavinfo import WavInfoReader\n",
        "from random import shuffle, seed\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class audio_generator():\n",
        "    '''\n",
        "    Class to create a Tensorflow dataset based on an iterator from a large scale\n",
        "    audio dataset. This audio generator only supports single channel audio files.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, path_to_input, path_to_s1, len_of_samples, fs, train_flag=False):\n",
        "        '''\n",
        "        Constructor of the audio generator class.\n",
        "        '''\n",
        "        self.path_to_input = path_to_input\n",
        "        self.path_to_s1 = path_to_s1\n",
        "        self.len_of_samples = len_of_samples\n",
        "        self.fs = fs\n",
        "        self.train_flag=train_flag\n",
        "        self.count_samples()\n",
        "        self.create_tf_data_obj()\n",
        "\n",
        "    def count_samples(self):\n",
        "        '''Method to list the data of the dataset and count the number of samples.'''\n",
        "        self.file_names = fnmatch.filter(os.listdir(self.path_to_input), '*.wav')\n",
        "        self.total_samples = 0\n",
        "        for file in self.file_names:\n",
        "            info = WavInfoReader(os.path.join(self.path_to_input, file))\n",
        "            self.total_samples = self.total_samples + \\\n",
        "                int(np.fix(info.data.frame_count/self.len_of_samples))\n",
        "\n",
        "    def create_generator(self):\n",
        "        '''Method to create the iterator.'''\n",
        "        if self.train_flag:\n",
        "            shuffle(self.file_names)\n",
        "        for file in self.file_names:\n",
        "            noisy, fs_1 = sf.read(os.path.join(self.path_to_input, file))\n",
        "            speech, fs_2 = sf.read(os.path.join(self.path_to_s1, file))  # Same filename\n",
        "\n",
        "            if fs_1 != self.fs or fs_2 != self.fs:\n",
        "                raise ValueError('Sampling rates do not match.')\n",
        "            if noisy.ndim != 1 or speech.ndim != 1:\n",
        "                raise ValueError('Too many audio channels.')\n",
        "\n",
        "            num_samples = int(np.fix(noisy.shape[0]/self.len_of_samples))\n",
        "            for idx in range(num_samples):\n",
        "                in_dat = noisy[int(idx*self.len_of_samples):int((idx+1)*self.len_of_samples)]\n",
        "                tar_dat = speech[int(idx*self.len_of_samples):int((idx+1)*self.len_of_samples)]\n",
        "                yield in_dat.astype('float32'), tar_dat.astype('float32')\n",
        "\n",
        "    def create_tf_data_obj(self):\n",
        "        '''Method to create the tf.data.Dataset.'''\n",
        "        self.tf_data_set = tf.data.Dataset.from_generator(\n",
        "                        self.create_generator,\n",
        "                        (tf.float32, tf.float32),\n",
        "                        output_shapes=(tf.TensorShape([self.len_of_samples]),\n",
        "                                       tf.TensorShape([self.len_of_samples])),\n",
        "                        args=None)\n",
        "\n",
        "\n",
        "class InstantLayerNormalization(Layer):\n",
        "    '''Instant layer normalization layer'''\n",
        "    def __init__(self, **kwargs):\n",
        "        super(InstantLayerNormalization, self).__init__(**kwargs)\n",
        "        self.epsilon = 1e-7\n",
        "        self.gamma = None\n",
        "        self.beta = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        shape = input_shape[-1:]\n",
        "        self.gamma = self.add_weight(shape=shape, initializer='ones', trainable=True, name='gamma')\n",
        "        self.beta = self.add_weight(shape=shape, initializer='zeros', trainable=True, name='beta')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mean = tf.math.reduce_mean(inputs, axis=[-1], keepdims=True)\n",
        "        variance = tf.math.reduce_mean(tf.math.square(inputs - mean), axis=[-1], keepdims=True)\n",
        "        std = tf.math.sqrt(variance + self.epsilon)\n",
        "        outputs = (inputs - mean) / std\n",
        "        outputs = outputs * self.gamma + self.beta\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class DTLN_model():\n",
        "    '''Class to create and train the DTLN model'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cost_function = self.snr_cost\n",
        "        self.model = []\n",
        "        # Default parameters\n",
        "        self.fs = 16000\n",
        "        self.batchsize = 64\n",
        "        self.len_samples = 15\n",
        "        self.activation = 'sigmoid'\n",
        "        self.numUnits = 128\n",
        "        self.numLayer = 2\n",
        "        self.blockLen = 512\n",
        "        self.block_shift = 128\n",
        "        self.dropout = 0.25\n",
        "        self.lr = 1e-3\n",
        "        self.max_epochs = 100\n",
        "        self.encoder_size = 256\n",
        "        self.eps = 1e-7\n",
        "\n",
        "        # Set seeds\n",
        "        os.environ['PYTHONHASHSEED']=str(42)\n",
        "        seed(42)\n",
        "        np.random.seed(42)\n",
        "        tf.random.set_seed(42)\n",
        "\n",
        "        # GPU memory growth\n",
        "        physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "        if len(physical_devices) > 0:\n",
        "            for device in physical_devices:\n",
        "                tf.config.experimental.set_memory_growth(device, enable=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def snr_cost(s_estimate, s_true):\n",
        "        '''SNR cost function'''\n",
        "        snr = tf.reduce_mean(tf.math.square(s_true), axis=-1, keepdims=True) / \\\n",
        "            (tf.reduce_mean(tf.math.square(s_true-s_estimate), axis=-1, keepdims=True)+1e-7)\n",
        "        num = tf.math.log(snr)\n",
        "        denom = tf.math.log(tf.constant(10, dtype=num.dtype))\n",
        "        loss = -10*(num / (denom))\n",
        "        return loss\n",
        "\n",
        "    def lossWrapper(self):\n",
        "        '''Wrapper for loss function'''\n",
        "        def lossFunction(y_true,y_pred):\n",
        "            loss = tf.squeeze(self.cost_function(y_pred,y_true))\n",
        "            loss = tf.reduce_mean(loss)\n",
        "            return loss\n",
        "        return lossFunction\n",
        "\n",
        "    def stftLayer(self, x):\n",
        "        '''STFT layer'''\n",
        "        frames = tf.signal.frame(x, self.blockLen, self.block_shift)\n",
        "        stft_dat = tf.signal.rfft(frames)\n",
        "        mag = tf.abs(stft_dat)\n",
        "        phase = tf.math.angle(stft_dat)\n",
        "        return [mag, phase]\n",
        "\n",
        "    def fftLayer(self, x):\n",
        "        '''FFT layer'''\n",
        "        frame = tf.expand_dims(x, axis=1)\n",
        "        stft_dat = tf.signal.rfft(frame)\n",
        "        mag = tf.abs(stft_dat)\n",
        "        phase = tf.math.angle(stft_dat)\n",
        "        return [mag, phase]\n",
        "\n",
        "    def ifftLayer(self, x):\n",
        "        '''Inverse FFT layer'''\n",
        "        s1_stft = (tf.cast(x[0], tf.complex64) * tf.exp( (1j * tf.cast(x[1], tf.complex64))))\n",
        "        return tf.signal.irfft(s1_stft)\n",
        "\n",
        "    def overlapAddLayer(self, x):\n",
        "        '''Overlap and add layer'''\n",
        "        return tf.signal.overlap_and_add(x, self.block_shift)\n",
        "\n",
        "    def seperation_kernel(self, num_layer, mask_size, x, stateful=False):\n",
        "        '''Separation kernel with LSTM layers'''\n",
        "        for idx in range(num_layer):\n",
        "            x = LSTM(self.numUnits, return_sequences=True, stateful=stateful)(x)\n",
        "            if idx<(num_layer-1):\n",
        "                x = Dropout(self.dropout)(x)\n",
        "        mask = Dense(mask_size)(x)\n",
        "        mask = Activation(self.activation)(mask)\n",
        "        return mask\n",
        "\n",
        "    def build_DTLN_model(self, norm_stft=False):\n",
        "        '''Build DTLN model'''\n",
        "        time_dat = Input(batch_shape=(None, None))\n",
        "        mag,angle = Lambda(self.stftLayer)(time_dat)\n",
        "\n",
        "        if norm_stft:\n",
        "            mag_norm = InstantLayerNormalization()(tf.math.log(mag + 1e-7))\n",
        "        else:\n",
        "            mag_norm = mag\n",
        "\n",
        "        mask_1 = self.seperation_kernel(self.numLayer, (self.blockLen//2+1), mag_norm)\n",
        "        estimated_mag = Multiply()([mag, mask_1])\n",
        "        estimated_frames_1 = Lambda(self.ifftLayer)([estimated_mag,angle])\n",
        "        encoded_frames = Conv1D(self.encoder_size,1,strides=1,use_bias=False)(estimated_frames_1)\n",
        "        encoded_frames_norm = InstantLayerNormalization()(encoded_frames)\n",
        "        mask_2 = self.seperation_kernel(self.numLayer, self.encoder_size, encoded_frames_norm)\n",
        "        estimated = Multiply()([encoded_frames, mask_2])\n",
        "        decoded_frames = Conv1D(self.blockLen, 1, padding='causal',use_bias=False)(estimated)\n",
        "        estimated_sig = Lambda(self.overlapAddLayer)(decoded_frames)\n",
        "\n",
        "        self.model = Model(inputs=time_dat, outputs=estimated_sig)\n",
        "        print(self.model.summary())\n",
        "\n",
        "    def compile_model(self):\n",
        "        '''Compile model with optimizer and loss'''\n",
        "        optimizerAdam = keras.optimizers.Adam(learning_rate=self.lr, clipnorm=3.0)\n",
        "        self.model.compile(loss=self.lossWrapper(), optimizer=optimizerAdam)\n",
        "\n",
        "print(\"âœ… DTLN model code loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5gi-9gRuRgp"
      },
      "source": [
        "## 5. Check Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHo04dcvuRgq",
        "outputId": "86cbb39f-9de9-44fc-9940-79f6beba9ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Checking datasets...\n",
            "\n",
            "âœ… Training Noisy: 9936 files found at vivos_datasets/train/noisy\n",
            "âœ… Training Clean: 9937 files found at vivos_datasets/train/clean\n",
            "âœ… Validation Noisy: 1242 files found at vivos_datasets/val/noisy\n",
            "âœ… Validation Clean: 1242 files found at vivos_datasets/val/clean\n",
            "\n",
            "âœ… All dataset paths are valid!\n",
            "\n",
            "ğŸ“Š Dataset info:\n",
            "   Train pairs: 9,936\n",
            "   Val pairs:   1,242\n",
            "   Total pairs: 11,178\n"
          ]
        }
      ],
      "source": [
        "import fnmatch\n",
        "\n",
        "def check_dataset_path(path, name):\n",
        "    \"\"\"Check if dataset path exists and count files\"\"\"\n",
        "    if os.path.exists(path):\n",
        "        files = fnmatch.filter(os.listdir(path), '*.wav')\n",
        "        print(f\"âœ… {name}: {len(files)} files found at {path}\")\n",
        "        return len(files)\n",
        "    else:\n",
        "        print(f\"âŒ {name}: Path not found - {path}\")\n",
        "        return 0\n",
        "\n",
        "print(\"ğŸ” Checking datasets...\\n\")\n",
        "train_noisy = check_dataset_path(PATH_TO_TRAIN_MIX, \"Training Noisy\")\n",
        "train_clean = check_dataset_path(PATH_TO_TRAIN_SPEECH, \"Training Clean\")\n",
        "val_noisy = check_dataset_path(PATH_TO_VAL_MIX, \"Validation Noisy\")\n",
        "val_clean = check_dataset_path(PATH_TO_VAL_SPEECH, \"Validation Clean\")\n",
        "\n",
        "if train_noisy > 0 and train_clean > 0 and val_noisy > 0 and val_clean > 0:\n",
        "    print(\"\\nâœ… All dataset paths are valid!\")\n",
        "    print(f\"\\nğŸ“Š Dataset info:\")\n",
        "    print(f\"   Train pairs: {train_noisy:,}\")\n",
        "    print(f\"   Val pairs:   {val_noisy:,}\")\n",
        "    print(f\"   Total pairs: {train_noisy + val_noisy:,}\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ Warning: Some dataset paths are missing or empty!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn-RMxIhuRgq"
      },
      "source": [
        "## 6. Create and Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TBIwOkjKuRgq",
        "outputId": "2367a5d3-583b-4cf3-8615-383f04efee6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ—ï¸ Building DTLN model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚            â”‚                   â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>)]       â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> â”‚ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,153</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> â”‚ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ instant_layer_normâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstantLayerNormaâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> â”‚ instant_layer_noâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_1          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> â”‚ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lambda (\u001b[38;5;33mLambda\u001b[0m)     â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m257\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â”‚            â”‚                   â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m)]       â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) â”‚    \u001b[38;5;34m197,632\u001b[0m â”‚ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) â”‚    \u001b[38;5;34m131,584\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m) â”‚     \u001b[38;5;34m33,153\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply (\u001b[38;5;33mMultiply\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚    \u001b[38;5;34m131,072\u001b[0m â”‚ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ instant_layer_normâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mInstantLayerNormaâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) â”‚    \u001b[38;5;34m197,120\u001b[0m â”‚ instant_layer_noâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) â”‚    \u001b[38;5;34m131,584\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚     \u001b[38;5;34m33,024\u001b[0m â”‚ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_1          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚    \u001b[38;5;34m131,072\u001b[0m â”‚ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">986,753</span> (3.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m986,753\u001b[0m (3.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">986,753</span> (3.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m986,753\u001b[0m (3.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "\n",
            "âœ… Model built successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create model instance\n",
        "model_trainer = DTLN_model()\n",
        "\n",
        "# Set custom parameters\n",
        "model_trainer.batchsize = BATCH_SIZE\n",
        "model_trainer.max_epochs = MAX_EPOCHS\n",
        "model_trainer.lr = LEARNING_RATE\n",
        "model_trainer.len_samples = SAMPLE_LENGTH_SECONDS\n",
        "\n",
        "# Build the model\n",
        "print(\"ğŸ—ï¸ Building DTLN model...\")\n",
        "model_trainer.build_DTLN_model(norm_stft=False)\n",
        "print(\"\\nâœ… Model built successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeDgvp30uRgr"
      },
      "source": [
        "## 7. Load Checkpoint (if resuming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX2ILJTpuRgr",
        "outputId": "9006b546-685d-4d86-bab0-17191c2be7ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â„¹ï¸ No checkpoint found. Starting training from scratch...\n",
            "\n",
            "ğŸ Will start training from epoch: 1\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import re\n",
        "\n",
        "def get_latest_checkpoint(checkpoint_dir, run_name):\n",
        "    \"\"\"Find the latest checkpoint file\"\"\"\n",
        "    pattern = os.path.join(checkpoint_dir, f\"{run_name}_epoch_*.weights.weights.h5\")\n",
        "    checkpoints = glob.glob(pattern)\n",
        "\n",
        "    if not checkpoints:\n",
        "        main_checkpoint = os.path.join(checkpoint_dir, f\"{run_name}.weights.h5\")\n",
        "        if os.path.exists(main_checkpoint):\n",
        "            return main_checkpoint, 0\n",
        "        return None, 0\n",
        "\n",
        "    checkpoint_epochs = []\n",
        "    for cp in checkpoints:\n",
        "        match = re.search(r'epoch_(\\d+)', cp)\n",
        "        if match:\n",
        "            checkpoint_epochs.append((int(match.group(1)), cp))\n",
        "\n",
        "    if checkpoint_epochs:\n",
        "        checkpoint_epochs.sort(reverse=True)\n",
        "        latest_epoch, latest_checkpoint = checkpoint_epochs[0]\n",
        "        return latest_checkpoint, latest_epoch\n",
        "\n",
        "    return None, 0\n",
        "\n",
        "# Check for existing checkpoints\n",
        "initial_epoch = 0\n",
        "\n",
        "if RESUME_FROM_CHECKPOINT:\n",
        "    latest_checkpoint, checkpoint_epoch = get_latest_checkpoint(CHECKPOINT_DIR, RUN_NAME)\n",
        "\n",
        "    if latest_checkpoint:\n",
        "        print(f\"ğŸ“¥ Loading checkpoint from: {latest_checkpoint}\")\n",
        "        print(f\"ğŸ“Š Resuming from epoch: {checkpoint_epoch}\")\n",
        "        try:\n",
        "            model_trainer.model.load_weights(latest_checkpoint)\n",
        "            initial_epoch = checkpoint_epoch\n",
        "            print(\"âœ… Checkpoint loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Failed to load checkpoint: {e}\")\n",
        "            print(\"Starting training from scratch...\")\n",
        "            initial_epoch = 0\n",
        "    else:\n",
        "        print(\"â„¹ï¸ No checkpoint found. Starting training from scratch...\")\n",
        "else:\n",
        "    print(\"â„¹ï¸ Resume from checkpoint disabled. Starting fresh training...\")\n",
        "\n",
        "print(f\"\\nğŸ Will start training from epoch: {initial_epoch + 1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xmqb3AbuRgr"
      },
      "source": [
        "## 8. Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9erk9hSAuRgr",
        "outputId": "87d70ff2-189d-42a8-9b64-c0fd31347ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš™ï¸ Compiling model...\n",
            "âœ… Model compiled successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"âš™ï¸ Compiling model...\")\n",
        "model_trainer.compile_model()\n",
        "print(\"âœ… Model compiled successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeUB1ZbguRgr"
      },
      "source": [
        "## 9. Setup Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Kfw68OuRgr",
        "outputId": "480d659f-3b37-45b6-8007-86145809f8ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Training callbacks configured!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "import shutil\n",
        "\n",
        "class DriveCheckpointCallback(Callback):\n",
        "    \"\"\"Custom callback to save checkpoint to Google Drive after each epoch\"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir, run_name):\n",
        "        super().__init__()\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.run_name = run_name\n",
        "        self.best_val_loss = float('inf')\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Save epoch checkpoint\n",
        "        epoch_checkpoint_path = os.path.join(\n",
        "            self.checkpoint_dir,\n",
        "            f\"{self.run_name}_epoch_{epoch+1:03d}.weights.h5\"\n",
        "        )\n",
        "\n",
        "        print(f\"\\nğŸ’¾ Saving checkpoint to Google Drive: {epoch_checkpoint_path}\")\n",
        "        self.model.save_weights(epoch_checkpoint_path)\n",
        "\n",
        "        # Save as latest\n",
        "        latest_checkpoint_path = os.path.join(\n",
        "            self.checkpoint_dir,\n",
        "            f\"{self.run_name}_latest.weights.h5\"\n",
        "        )\n",
        "        shutil.copy(epoch_checkpoint_path, latest_checkpoint_path)\n",
        "\n",
        "        # Save best model\n",
        "        val_loss = logs.get('val_loss')\n",
        "        if val_loss and val_loss < self.best_val_loss:\n",
        "            self.best_val_loss = val_loss\n",
        "            best_checkpoint_path = os.path.join(\n",
        "                self.checkpoint_dir,\n",
        "                f\"{self.run_name}_best.weights.h5\"\n",
        "            )\n",
        "            shutil.copy(epoch_checkpoint_path, best_checkpoint_path)\n",
        "            print(f\"â­ New best model saved! Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Keep only last 3 epoch checkpoints\n",
        "        self._cleanup_old_checkpoints(keep_last=3)\n",
        "        print(f\"âœ… Checkpoint saved successfully!\")\n",
        "\n",
        "    def _cleanup_old_checkpoints(self, keep_last=3):\n",
        "        pattern = os.path.join(self.checkpoint_dir, f\"{self.run_name}_epoch_*.weights.h5\")\n",
        "        checkpoints = glob.glob(pattern)\n",
        "\n",
        "        if len(checkpoints) > keep_last:\n",
        "            checkpoints.sort(key=os.path.getmtime)\n",
        "            for old_checkpoint in checkpoints[:-keep_last]:\n",
        "                try:\n",
        "                    os.remove(old_checkpoint)\n",
        "                    print(f\"ğŸ—‘ï¸ Removed old checkpoint: {os.path.basename(old_checkpoint)}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ Failed to remove {old_checkpoint}: {e}\")\n",
        "\n",
        "# Create callbacks\n",
        "save_path = os.path.join(CHECKPOINT_DIR, RUN_NAME)\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "drive_checkpoint_callback = DriveCheckpointCallback(CHECKPOINT_DIR, RUN_NAME)\n",
        "csv_logger = CSVLogger(os.path.join(save_path, f'training_{RUN_NAME}.log'), append=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-10, cooldown=1, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto', baseline=None)\n",
        "\n",
        "callbacks = [\n",
        "    drive_checkpoint_callback,\n",
        "    csv_logger,\n",
        "    reduce_lr,\n",
        "    early_stopping\n",
        "]\n",
        "\n",
        "print(\"âœ… Training callbacks configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yguUDQouuRgs"
      },
      "source": [
        "## 10. Prepare Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrdbJCdtuRgs",
        "outputId": "a3292f84-085b-4855-9d25-81c1bb68a73b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸµ Audio sample length: 48000 samples (3.00 seconds)\n",
            "\n",
            "ğŸ“Š Creating data generators...\n",
            "   Loading training data...\n",
            "   âœ… Training samples: 10,276\n",
            "   âœ… Training steps per epoch: 160\n",
            "\n",
            "   Loading validation data...\n",
            "   âœ… Validation samples: 1,316\n",
            "   âœ… Validation steps: 20\n",
            "\n",
            "âœ… Data generators ready!\n"
          ]
        }
      ],
      "source": [
        "# Calculate sample length\n",
        "len_in_samples = int(np.fix(\n",
        "    model_trainer.fs * model_trainer.len_samples / model_trainer.block_shift\n",
        ") * model_trainer.block_shift)\n",
        "\n",
        "print(f\"ğŸµ Audio sample length: {len_in_samples} samples ({len_in_samples/model_trainer.fs:.2f} seconds)\")\n",
        "print(f\"\\nğŸ“Š Creating data generators...\")\n",
        "\n",
        "# Create training data generator\n",
        "print(\"   Loading training data...\")\n",
        "generator_input = audio_generator(\n",
        "    PATH_TO_TRAIN_MIX,\n",
        "    PATH_TO_TRAIN_SPEECH,\n",
        "    len_in_samples,\n",
        "    model_trainer.fs,\n",
        "    train_flag=True\n",
        ")\n",
        "\n",
        "dataset = generator_input.tf_data_set\n",
        "dataset = dataset.batch(model_trainer.batchsize, drop_remainder=True).repeat()\n",
        "steps_train = generator_input.total_samples // model_trainer.batchsize\n",
        "\n",
        "print(f\"   âœ… Training samples: {generator_input.total_samples:,}\")\n",
        "print(f\"   âœ… Training steps per epoch: {steps_train:,}\")\n",
        "\n",
        "# Create validation data generator\n",
        "print(\"\\n   Loading validation data...\")\n",
        "generator_val = audio_generator(\n",
        "    PATH_TO_VAL_MIX,\n",
        "    PATH_TO_VAL_SPEECH,\n",
        "    len_in_samples,\n",
        "    model_trainer.fs\n",
        ")\n",
        "\n",
        "dataset_val = generator_val.tf_data_set\n",
        "dataset_val = dataset_val.batch(model_trainer.batchsize, drop_remainder=True).repeat()\n",
        "steps_val = generator_val.total_samples // model_trainer.batchsize\n",
        "\n",
        "print(f\"   âœ… Validation samples: {generator_val.total_samples:,}\")\n",
        "print(f\"   âœ… Validation steps: {steps_val:,}\")\n",
        "\n",
        "print(\"\\nâœ… Data generators ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjcU0wKruRgs"
      },
      "source": [
        "## 11. Start Training ğŸš€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhs9Olc5uRgs",
        "outputId": "b52161a4-eb76-4e6a-a969-a94e6755c398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ğŸš€ STARTING TRAINING\n",
            "============================================================\n",
            "ğŸ“Š Configuration:\n",
            "   Batch size: 64\n",
            "   Max epochs: 100\n",
            "   Initial epoch: 1\n",
            "   Learning rate: 0.001\n",
            "   Training steps: 160\n",
            "   Validation steps: 20\n",
            "\n",
            "ğŸ’¾ Checkpoints will be saved to: vivos_checkpoints\n",
            "============================================================\n",
            "\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - loss: -4.9872 \n",
            "ğŸ’¾ Saving checkpoint to Google Drive: vivos_checkpoints/DTLN_vivos_epoch_001.weights.h5\n",
            "â­ New best model saved! Val Loss: -9.8561\n",
            "ğŸ—‘ï¸ Removed old checkpoint: DTLN_vivos_epoch_030.weights.h5\n",
            "âœ… Checkpoint saved successfully!\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3933s\u001b[0m 24s/step - loss: -5.0031 - val_loss: -9.8561 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - loss: -10.4711\n",
            "ğŸ’¾ Saving checkpoint to Google Drive: vivos_checkpoints/DTLN_vivos_epoch_002.weights.h5\n",
            "â­ New best model saved! Val Loss: -10.9103\n",
            "ğŸ—‘ï¸ Removed old checkpoint: DTLN_vivos_epoch_031.weights.h5\n",
            "âœ… Checkpoint saved successfully!\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 7s/step - loss: -10.4729 - val_loss: -10.9103 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 62/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m10:17\u001b[0m 6s/step - loss: -10.9404"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ğŸš€ STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"ğŸ“Š Configuration:\")\n",
        "print(f\"   Batch size: {model_trainer.batchsize}\")\n",
        "print(f\"   Max epochs: {model_trainer.max_epochs}\")\n",
        "print(f\"   Initial epoch: {initial_epoch + 1}\")\n",
        "print(f\"   Learning rate: {model_trainer.lr}\")\n",
        "print(f\"   Training steps: {steps_train:,}\")\n",
        "print(f\"   Validation steps: {steps_val:,}\")\n",
        "print(f\"\\nğŸ’¾ Checkpoints will be saved to: {CHECKPOINT_DIR}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Start training\n",
        "history = model_trainer.model.fit(\n",
        "    x=dataset,\n",
        "    batch_size=None,\n",
        "    steps_per_epoch=steps_train,\n",
        "    epochs=model_trainer.max_epochs,\n",
        "    initial_epoch=initial_epoch,\n",
        "    verbose=1,\n",
        "    validation_data=dataset_val,\n",
        "    validation_steps=steps_val,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… TRAINING COMPLETED!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYNvyB__uRgt"
      },
      "source": [
        "## 12. Plot Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9CEdsIGuRgt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss (Log Scale)')\n",
        "plt.ylabel('Loss (log)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, f'{RUN_NAME}_training_history.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ… Training history plot saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljoidxKxuRgt"
      },
      "source": [
        "## 13. Save Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmvEO_KjuRgt"
      },
      "outputs": [],
      "source": [
        "# Save final model weights\n",
        "final_model_path = os.path.join(CHECKPOINT_DIR, f\"{RUN_NAME}_final.weights.h5\")\n",
        "model_trainer.model.save_weights(final_model_path)\n",
        "print(f\"âœ… Final model saved to: {final_model_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"  TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"âœ… Training completed successfully!\")\n",
        "print(f\"\\nğŸ“ All files saved to Google Drive:\")\n",
        "print(f\"   Location: {CHECKPOINT_DIR}\")\n",
        "print(f\"\\nğŸ’¾ Checkpoint files:\")\n",
        "print(f\"   â€¢ Best model: {RUN_NAME}_best.weights.h5\")\n",
        "print(f\"   â€¢ Final model: {RUN_NAME}_final.weights.h5\")\n",
        "print(f\"   â€¢ Latest checkpoint: {RUN_NAME}_latest.weights.h5\")\n",
        "print(f\"\\nğŸ“ˆ Training log:\")\n",
        "print(f\"   â€¢ training_{RUN_NAME}.log\")\n",
        "print(f\"\\nğŸ¨ Visualization:\")\n",
        "print(f\"   â€¢ {RUN_NAME}_training_history.png\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ¨ To resume training later, just run this notebook again!\")\n",
        "print(\"âœ¨ Make sure RESUME_FROM_CHECKPOINT = True\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}